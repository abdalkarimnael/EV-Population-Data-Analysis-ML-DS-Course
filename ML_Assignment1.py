# -*- coding: utf-8 -*-
"""ML-Assighment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQcu4wlUf9VDDh-KliGknvTMuUynIlvR

#ML-Assighment1:Machine Learning and Data Science

**Razi Atyani 1200028**<br>
**Abdalkarim Eiss 1200015**

##Data Cleaning and Feature Engineering:

###Libraries:
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from scipy.stats import zscore
import geopandas as gpd
from shapely import wkt
import folium

"""###Read the dataset:"""

# data frame
df = pd.read_csv('Electric_Vehicle_Population_Data.csv')
# explore the dataset
df.head()

#Info about data
df.info()

# Shape about data
df.shape

"""###Document Missing Values:"""

# The sum of missing values in each column
df.isnull().sum()

# The percent of missing values from all dataset
print(df.isnull().any(axis=1).sum())
print(100*df.isnull().any(axis=1).sum()/df.shape[0],'%')

#the records with missing values
df[df.isnull().any(axis=1)]

#the duplicated rows
df[df.duplicated()].sum()

# The number of empty records
print(f"Number of empty records = {df.isnull().all(axis=1).sum()}")
df[df.isnull().all(axis=1)]

#missing percentage
missing_percentage = (df.isnull().sum().sort_values(ascending = False)/len(df))*100
missing_percentage

# drop null values
df.dropna(subset=['Vehicle Location'], inplace=True)
df.dropna(subset=['County'], inplace=True)
df.dropna(subset=['Postal Code'], inplace=True)
df.dropna(subset=['Electric Utility'], inplace=True)
df.dropna(subset=['City'], inplace=True)
df.dropna(subset=['2020 Census Tract'], inplace=True)
df.dropna(subset=['Base MSRP'], inplace=True)
df.dropna(subset=['Electric Range'], inplace=True)
print(df.isnull().sum())

print(f"The number of records where Legislative District is missing equals {df.isnull()['Legislative District'].sum()}")
print(f"The proportion of records where Legislative District is missing equals {100*df.isnull()['Legislative District'].sum()/df.shape[0]}%")

# Grouping by 'Legislative District' and
df_Legislative = df.groupby('Legislative District')['Postal Code'].count()

# Creating a larger bar plot with rotated x-axis labels
plt.figure(figsize=(12, 6))
df_Legislative.plot(kind='bar')
plt.xlabel('Legislative District')
plt.ylabel('Count')

# Rotating the x-axis labels for better visibility
plt.xticks(rotation=90)


plt.show()

# Calculating and printing the relative frequency
relative_frequency = df.groupby('Legislative District')['Postal Code'].count() / df['Legislative District'].shape[0]
print(relative_frequency)

"""###Handling the Missing Values:

"""

# Strategy 1: Dropping the rows with missing values in Legislative District column
df_dropped = df.dropna(subset=['Legislative District'])
print(df_dropped.shape)

# Strategy 2: Using Mean/Median Imputation
# Mean Imputation
df_mean_imputed = df.copy()
df_mean_imputed['Legislative District'] = df_mean_imputed['Legislative District'].fillna(df_mean_imputed['Legislative District'].mean())
#Median Imputation
df_median_imputed = df.copy()
df_median_imputed['Legislative District'] = df_median_imputed['Legislative District'].fillna(df_median_imputed['Legislative District'].median())

# Compare the impact on analysis
# The original data
print("Original Data:")
print(df.describe())

# After dropping rows
print("\nAfter Dropping Rows:")
print(df_dropped.describe())

# After mean imputation
print("\nAfter Mean Imputation:")
print(df_mean_imputed.describe())

# After median imputation
print("\nAfter Median Imputation:")
print(df_median_imputed.describe())

"""###Outliers:"""

df_dropped.describe()

for column in df_dropped.select_dtypes(include='number').columns:
    # Create a new figure for each column's boxplot
    plt.figure(figsize=(8, 6))
    # Plot the boxplot for the current column
    df_dropped.boxplot(column=[column])
    # Add a title to the boxplot for context
    plt.title(f'Boxplot for {column}')
    # Show the plot
    plt.show()

"""###Feature Engineering"""

enc = OneHotEncoder(handle_unknown='ignore')
enc.fit(df_dropped[["Make"]])
df_transform = enc.transform(df_dropped[["Make"]]).toarray()
# Create a copy of the original DataFrame to store the one-hot encoded data
df_ohenc = df_dropped.copy()
df_ohenc[enc.categories_[0]] = df_transform
#Copy
df_clean = df_ohenc.copy()
# Display the first few rows of the new DataFrame
df_ohenc.head()

enc = OneHotEncoder(handle_unknown='ignore')
enc.fit(df_dropped[["Model"]])
df_transform = enc.transform(df_dropped[["Model"]]).toarray()
# Create a copy of the original DataFrame to store the one-hot encoded data
df_ohenc = df_dropped.copy()
df_ohenc[enc.categories_[0]] = df_transform
# Display the first few rows of the new DataFrame
df_ohenc.head()

# List of multiple features for one-hot encoding
features_to_encode = ['County', 'City', 'Model', 'Make', 'Electric Vehicle Type',
                      'Clean Alternative Fuel Vehicle (CAFV) Eligibility', 'Electric Utility']

enc = OneHotEncoder(handle_unknown='ignore')
for feature in features_to_encode:
    enc.fit(df_dropped[[feature]])
    df_transform = enc.transform(df_dropped[[feature]]).toarray()
    # Create a copy of the original DataFrame to store the one-hot encoded data
df_ohenc = df_dropped.copy()
df_ohenc[enc.categories_[0]] = df_transform
# Display the first few rows of the new DataFrame
df_ohenc.head()

df_ohenc.info()

# Initialize the scaler
scaler = MinMaxScaler()
df_zScore = df_ohenc.copy()
# Apply normalization to the numeric columns (assuming you have numeric columns in df_ohenc)
numeric_cols = df_ohenc.select_dtypes(include=['float64', 'int64']).columns.tolist()

# Normalize the numeric columns
df_ohenc[numeric_cols] = scaler.fit_transform(df_ohenc[numeric_cols])

# Display the first few rows of the normalized DataFrame
print(df_ohenc.head())

# Apply z-score normalization to the numeric columns
df_zScore[numeric_cols] = df_zScore[numeric_cols].apply(zscore)
# Display the first few rows of the z-score normalized DataFrame
print(df_zScore.head())

#Summary statistics (mean, median, standard deviation) for numerical features
numerical_features = df_clean.select_dtypes(include=['float64', 'int64'])
summary_stats = numerical_features.agg(['mean', 'median', 'std'])
df_clean.describe()
print(summary_stats)

# Convert 'Vehicle Location' from WKT to geometry
df_clean['geometry'] = df_clean['Vehicle Location'].apply(wkt.loads)

# Create a GeoDataFrame from the original dataframe
gdf_ev = gpd.GeoDataFrame(df_clean, geometry='geometry')

# Set the coordinate reference system (CRS) to WGS84 (EPSG:4326)
gdf_ev.set_crs("EPSG:4326", inplace=True)

# Initialize a Folium map centered at the mean location of the points
mean_lat = gdf_ev.geometry.y.mean()
mean_lon = gdf_ev.geometry.x.mean()
m = folium.Map(location=[mean_lat, mean_lon], zoom_start=10)

# Add EV points to the map
for _, row in gdf_ev.iterrows():
    folium.CircleMarker(
        location=[row.geometry.y, row.geometry.x],
        radius=5,
        color="blue",
        fill=True,
        fill_color="blue",
        fill_opacity=0.5
    ).add_to(m)

# Set a title for the map (displayed in Jupyter, not directly in Folium)
print("Spatial Distribution of Electric Vehicles")

# Display the map
m

# Count the occurrences of each EV model
model_popularity = df_clean['Model'].value_counts()

# Convert to DataFrame for better visualization
model_popularity_df = model_popularity.reset_index()
model_popularity_df.columns = ['Model', 'Popularity']

# Display the popularity of each model
print(model_popularity_df)

# Plotting the popularity of EV models
plt.figure(figsize=(30, 15))
plt.bar(model_popularity_df['Model'], model_popularity_df['Popularity'], color='skyblue')
plt.title('Popularity of Different EV Models')
plt.xlabel('EV Models')
plt.ylabel('Popularity (Count)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# The relationship between every pair of numeric features
# create a copy of the original DataFrame to mainting the original DataFrame
df_corr=df.copy()
# Initialize the LabelEncoder
label_encoder = LabelEncoder()
# Fit and transform the categorical feature
df_corr['VIN (1-10)_encoded'] = label_encoder.fit_transform(df_corr['VIN (1-10)'])
df_corr['State_encoded'] = label_encoder.fit_transform(df_corr['State'])
df_corr['County_encoded'] = label_encoder.fit_transform(df_corr['County'])
df_corr['City_encoded'] = label_encoder.fit_transform(df_corr['City'])
df_corr['Make_encoded'] = label_encoder.fit_transform(df_corr['Make'])
df_corr['Model_encoded'] = label_encoder.fit_transform(df_corr['Model'])
df_corr['Electric Vehicle Type_encoded'] = label_encoder.fit_transform(df_corr['Electric Vehicle Type'])
df_corr['Clean Alternative Fuel Vehicle (CAFV) Eligibility_encoded'] = label_encoder.fit_transform(df_corr['Clean Alternative Fuel Vehicle (CAFV) Eligibility'])
df_corr['Electric Utility_encoded'] = label_encoder.fit_transform(df_corr['Electric Utility'])
df_corr['Vehicle Location_encoded'] = label_encoder.fit_transform(df_corr['Vehicle Location'])
# Drop categorical features
df_corr.drop(['VIN (1-10)', 'State', 'County', 'City', 'Make', 'Model', 'Electric Vehicle Type', 'Clean Alternative Fuel Vehicle (CAFV) Eligibility', 'Electric Utility', 'Vehicle Location'], axis=1, inplace=True)
df_corr.corr()

"""###Visualization:"""

# Plot histograms for numerical features
numerical_features = ['Electric Range', 'Base MSRP', 'Model Year']

plt.figure(figsize=(15, 10))
for i, feature in enumerate(numerical_features, 1):
    plt.subplot(2, 2, i)  # Adjust layout for multiple plots
    df[feature].hist(bins=20, color='skyblue', edgecolor='black')
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Create scatter plots between numerical features
plt.figure(figsize=(15, 6))

# Scatter plot between Base MSRP and Electric Range
plt.subplot(1, 2, 1)
plt.scatter(df['Base MSRP'], df['Electric Range'], alpha=0.5, color='blue')
plt.title('Base MSRP vs Electric Range')
plt.xlabel('Base MSRP')
plt.ylabel('Electric Range')
plt.grid()

# Scatter plot between Base MSRP and Model Year
plt.subplot(1, 2, 2)
plt.scatter(df['Base MSRP'], df['Model Year'], alpha=0.5, color='green')
plt.title('Base MSRP vs Model Year')
plt.xlabel('Base MSRP')
plt.ylabel('Model Year')
plt.grid()

plt.tight_layout()
plt.show()

# Create boxplots to compare Base MSRP across different Makes
plt.figure(figsize=(30, 12))
sns.boxplot(x='Make', y='Base MSRP', data=df)
plt.title('Base MSRP Distribution Across Different Makes')
plt.xticks(rotation=45)
plt.ylabel('Base MSRP')
plt.xlabel('Make')
plt.tight_layout()
plt.show()

# Boxplot for Model vs Base MSRP
plt.figure(figsize=(30, 12))
sns.boxplot(x='Model', y='Base MSRP', data=df)
plt.title('Base MSRP Distribution Across Different Models')
plt.xticks(rotation=45)
plt.ylabel('Base MSRP')
plt.xlabel('Model')
plt.tight_layout()
plt.show()

# Correlation heatmap for numerical features
correlation_matrix = df[['Electric Range', 'Base MSRP', 'Model Year', 'Legislative District', '2020 Census Tract']].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

# Count the number of EVs per City
city_counts = df['City'].value_counts().reset_index()
city_counts.columns = ['City', 'EV_Count']

# Count the number of EVs per County
county_counts = df['County'].value_counts().reset_index()
county_counts.columns = ['County', 'EV_Count']

# Plotting the distribution of EVs across cities
plt.figure(figsize=(12, 6))
sns.barplot(x='EV_Count', y='City', data=city_counts.head(10), palette='viridis')  # Show top 10 cities
plt.title('Top 10 Cities by Number of Electric Vehicles')
plt.xlabel('Number of Electric Vehicles')
plt.ylabel('City')
plt.show()

# Plotting the distribution of EVs across counties
plt.figure(figsize=(12, 6))
sns.barplot(x='EV_Count', y='County', data=county_counts.head(10), palette='plasma')  # Show top 10 counties
plt.title('Top 10 Counties by Number of Electric Vehicles')
plt.xlabel('Number of Electric Vehicles')
plt.ylabel('County')
plt.show()

# Create a pivot table for city and make
pivot_city_make = df.pivot_table(index='City', columns='Make', values='VIN (1-10)', aggfunc='count').fillna(0)

# Plotting the stacked bar chart for EVs by Make across Cities
pivot_city_make.plot(kind='bar', stacked=True, figsize=(30, 14), colormap='tab20')
plt.title('Distribution of Electric Vehicles by Make Across Cities')
plt.xlabel('City')
plt.ylabel('Number of Electric Vehicles')
plt.legend(title='Make', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

ev_adoption = df.groupby('Model Year').size().reset_index(name='Registrations')
ev_adoption = ev_adoption.sort_values('Model Year')
import matplotlib.pyplot as plt
plt.plot(ev_adoption['Model Year'], ev_adoption['Registrations'], marker='o')
plt.title('EV Registrations per Year')
plt.xlabel('Model Year')
plt.ylabel('Number of Registrations')
plt.show()
ev_adoption['YoY_Growth'] = ev_adoption['Registrations'].pct_change() * 100
print(ev_adoption)

model_popularity = df.groupby(['Model Year', 'Model']).size().reset_index(name='Registrations')

# Sort to get top models per year
top_models = model_popularity.sort_values(['Model Year', 'Registrations'], ascending=[True, False])
print(top_models)

yearly_totals = model_popularity.groupby('Model Year')['Registrations'].sum().reset_index()
model_popularity = model_popularity.merge(yearly_totals, on='Model Year', suffixes=('', '_Total'))
model_popularity['Market Share'] = (model_popularity['Registrations'] / model_popularity['Registrations_Total']) * 100

print(model_popularity[['Model Year', 'Model', 'Market Share']])

type_adoption = df.groupby(['Model Year', 'Electric Vehicle Type']).size().reset_index(name='Registrations')

# Pivot for easier plotting
pivot_type = type_adoption.pivot(index='Model Year', columns='Electric Vehicle Type', values='Registrations').fillna(0)

# Plotting
pivot_type.plot(kind='bar', stacked=True, figsize=(10, 6))
plt.title('EV Adoption by Vehicle Type')
plt.xlabel('Model Year')
plt.ylabel('Number of Registrations')
plt.show()